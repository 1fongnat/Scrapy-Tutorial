"#Upon running the Scrapy shell: 2020-01-21 11:58:45 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: tutorial) 2020-01-21 11:58:45"
"[scrapy.utils.log] INFO: Versions: lxml 4.4.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.6.5"
"|Anaconda, Inc.| (default, Apr 26 2018, 08:42:37) - [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0"
"(OpenSSL 1.1.1d 10 Sep 2019), cryptography 2.8, Platform Darwin-17.7.0-x86_64-i386-64bit 2020-01-21 11:58:45 [scrapy.crawler] INFO:"
"Overridden settings: {'BOT_NAME': 'tutorial', 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter', 'LOGSTATS_INTERVAL': 0,"
"'NEWSPIDER_MODULE': 'tutorial.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['tutorial.spiders']} 2020-01-21 11:58:45"
"[scrapy.extensions.telnet] INFO: Telnet Password: 28e324dfbfdcd91f 2020-01-21 11:58:45 [scrapy.middleware] INFO: Enabled"
"extensions: ['scrapy.extensions.corestats.CoreStats', 'scrapy.extensions.telnet.TelnetConsole',"
"'scrapy.extensions.memusage.MemoryUsage'] 2020-01-21 11:58:45 [scrapy.middleware] INFO: Enabled downloader middlewares:"
"['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware', 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',"
"'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',"
"'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',"
"'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware', 'scrapy.downloadermiddlewares.retry.RetryMiddleware',"
"'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',"
"'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',"
"'scrapy.downloadermiddlewares.redirect.RedirectMiddleware', 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',"
"'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware', 'scrapy.downloadermiddlewares.stats.DownloaderStats'] 2020-01-21"
"11:58:45 [scrapy.middleware] INFO: Enabled spider middlewares: ['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',"
"'scrapy.spidermiddlewares.offsite.OffsiteMiddleware', 'scrapy.spidermiddlewares.referer.RefererMiddleware',"
"'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware', 'scrapy.spidermiddlewares.depth.DepthMiddleware'] 2020-01-21 11:58:45"
"[scrapy.middleware] INFO: Enabled item pipelines: [] 2020-01-21 11:58:45 [scrapy.extensions.telnet] INFO: Telnet console listening on"
"127.0.0.1:6023 2020-01-21 11:58:45 [scrapy.core.engine] INFO: Spider opened 2020-01-21 11:58:46 [scrapy.core.engine] DEBUG:"
"Crawled (404) (referer: None) 2020-01-21 11:58:46 [scrapy.core.engine] DEBUG: Crawled (200) (referer: None) [s] Available Scrapy"
"objects: [s] scrapy scrapy module (contains scrapy.Request, scrapy.Selector, etc) [s] crawler [s] item {} [s] request [s] response <200"
"http://quotes.toscrape.com/page/1/> [s] settings [s] spider [s] Useful shortcuts: [s] fetch(url[, redirect=True]) Fetch URL and update local"
"objects (by default, redirects are followed) [s] fetch(req) Fetch a scrapy.Request and update local objects [s] shelp() Shell help (print this"
"help) [s] view(response) View response in a browser # Using the shell response.css('title') # Output: [] # Input"
"response.css('title::text').getall() # Output [‘Quotes to Scrape'] # Input response.css('title').getall() # Output [‘'] # Input"
"response.css('title::text').get() # Output 'Quotes to Scrape’ # Input response.css('title::text').re(r'Quotes.*') # Output ['Quotes to Scrape'] #"
"Input response.css('title::text').re(r'Q\w+') # Output ['Quotes'] # Input response.css('title::text').re(r'(\w+) to (\w+)') # Output ['Quotes',"
"'Scrape']"
""
