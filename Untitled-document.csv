"ï»¿# quotes_spider.py"
"import scrapy"
""
""
"class QuotesSpider(scrapy.Spider):"
"name = ""quotes"""
""
""
"def start_requests(self):"
"urls = ["
"'http://quotes.toscrape.com/page/1/',"
"'http://quotes.toscrape.com/page/2/',"
"]"
"for url in urls:"
"yield scrapy.Request(url=url, callback=self.parse)"
""
""
"def parse(self, response):"
"page = response.url.split(""/"")[-2]"
"filename = 'quotes-%s.html' % page"
"with open(filename, 'wb') as f:"
"f.write(response.body)"
"self.log('Saved file %s' % filename)"
""
""
"# Output:"
"2020-01-21 10:48:16 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: tutorial)"
"2020-01-21 10:48:17 [scrapy.utils.log] INFO: Versions: lxml 4.4.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.6.5 |Anaconda, Inc.| (default, Apr 26 2018, 08:42:37) - [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-17.7.0-x86_64-i386-64bit"
"2020-01-21 10:48:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'tutorial', 'NEWSPIDER_MODULE': 'tutorial.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['tutorial.spiders']}"
"2020-01-21 10:48:17 [scrapy.extensions.telnet] INFO: Telnet Password: 1f69affaa6b38d70"
"2020-01-21 10:48:17 [scrapy.middleware] INFO: Enabled extensions:"
"['scrapy.extensions.corestats.CoreStats',"
"'scrapy.extensions.telnet.TelnetConsole',"
"'scrapy.extensions.memusage.MemoryUsage',"
"'scrapy.extensions.logstats.LogStats']"
"2020-01-21 10:48:17 [scrapy.middleware] INFO: Enabled downloader middlewares:"
"['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',"
"'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',"
"'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',"
"'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',"
"'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',"
"'scrapy.downloadermiddlewares.retry.RetryMiddleware',"
"'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',"
"'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',"
"'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',"
"'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',"
"'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',"
"'scrapy.downloadermiddlewares.stats.DownloaderStats']"
"2020-01-21 10:48:17 [scrapy.middleware] INFO: Enabled spider middlewares:"
"['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',"
"'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',"
"'scrapy.spidermiddlewares.referer.RefererMiddleware',"
"'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',"
"'scrapy.spidermiddlewares.depth.DepthMiddleware']"
"2020-01-21 10:48:17 [scrapy.middleware] INFO: Enabled item pipelines:"
"[]"
"2020-01-21 10:48:17 [scrapy.core.engine] INFO: Spider opened"
"2020-01-21 10:48:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)"
"2020-01-21 10:48:17 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023"
"2020-01-21 10:48:17 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://quotes.toscrape.com/robots.txt> (referer: None)"
"2020-01-21 10:48:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/page/1/> (referer: None)"
"2020-01-21 10:48:18 [quotes] DEBUG: Saved file quotes-1.html"
"2020-01-21 10:48:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/page/2/> (referer: None)"
"2020-01-21 10:48:18 [quotes] DEBUG: Saved file quotes-2.html"
"2020-01-21 10:48:18 [scrapy.core.engine] INFO: Closing spider (finished)"
"2020-01-21 10:48:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:"
"{'downloader/request_bytes': 678,"
"'downloader/request_count': 3,"
"'downloader/request_method_count/GET': 3,"
"'downloader/response_bytes': 6003,"
"'downloader/response_count': 3,"
"'downloader/response_status_count/200': 2,"
"'downloader/response_status_count/404': 1,"
"'elapsed_time_seconds': 0.862257,"
"'finish_reason': 'finished',"
"'finish_time': datetime.datetime(2020, 1, 21, 15, 48, 18, 212004),"
"'log_count/DEBUG': 5,"
"'log_count/INFO': 10,"
"'memusage/max': 50593792,"
"'memusage/startup': 50593792,"
"'response_received_count': 3,"
"'robotstxt/request_count': 1,"
"'robotstxt/response_count': 1,"
"'robotstxt/response_status_count/404': 1,"
"'scheduler/dequeued': 2,"
"'scheduler/dequeued/memory': 2,"
"'scheduler/enqueued': 2,"
"'scheduler/enqueued/memory': 2,"
"'start_time': datetime.datetime(2020, 1, 21, 15, 48, 17, 349747)}"
"2020-01-21 10:48:18 [scrapy.core.engine] INFO: Spider closed (finished)"
